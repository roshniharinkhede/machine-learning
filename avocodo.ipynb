{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq84/9EYw3lTS6kpuCAO+J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roshniharinkhede/machine-learning/blob/main/avocodo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aCCcs0DJeovA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/roshniharinkhede/Dataset/main/avocado.csv'"
      ],
      "metadata": {
        "id": "_Us5vpcFfZ0s"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "8f8XW3vZfnzj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQfUvXTFggp-",
        "outputId": "19a1973e-06aa-4a61-88a6-6d0b8db291cf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0      0\n",
              "Date            0\n",
              "AveragePrice    0\n",
              "Total Volume    0\n",
              "4046            0\n",
              "4225            0\n",
              "4770            0\n",
              "Total Bags      0\n",
              "Small Bags      0\n",
              "Large Bags      0\n",
              "XLarge Bags     0\n",
              "type            0\n",
              "year            0\n",
              "region          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(['Unnamed: 0'], axis = 1)"
      ],
      "metadata": {
        "id": "jnc7r11xlX0J"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.rename(index=str, columns={\"4046\" : \"Small Hass\", \"4225\" : \"Large Hass\",\"4770\" : \"XLarge Hass\" })"
      ],
      "metadata": {
        "id": "mv2xZW6wlof3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Date'] = pd.to_datetime(data['Date'])"
      ],
      "metadata": {
        "id": "aLzHO4Fylt3a"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avocodo = data.iloc[:,[1,3,4,5,6,7,8,9,10,11,12]]"
      ],
      "metadata": {
        "id": "SaxRsf3yl1-l"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avocodo.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fQ_gUgi-l_L3",
        "outputId": "41f272d0-9f20-488f-d564-b88ba47a8065"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   AveragePrice  Small Hass  Large Hass  XLarge Hass  Total Bags  Small Bags  \\\n",
              "0          1.33     1036.74    54454.85        48.16     8696.87     8603.62   \n",
              "1          1.35      674.28    44638.81        58.33     9505.56     9408.07   \n",
              "2          0.93      794.70   109149.67       130.50     8145.35     8042.21   \n",
              "3          1.08     1132.00    71976.41        72.58     5811.16     5677.40   \n",
              "4          1.28      941.48    43838.39        75.78     6183.95     5986.26   \n",
              "\n",
              "   Large Bags  XLarge Bags          type  year  region  \n",
              "0       93.25          0.0  conventional  2015  Albany  \n",
              "1       97.49          0.0  conventional  2015  Albany  \n",
              "2      103.14          0.0  conventional  2015  Albany  \n",
              "3      133.76          0.0  conventional  2015  Albany  \n",
              "4      197.69          0.0  conventional  2015  Albany  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4506194-7fd1-4667-9148-8c5de577cf00\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AveragePrice</th>\n",
              "      <th>Small Hass</th>\n",
              "      <th>Large Hass</th>\n",
              "      <th>XLarge Hass</th>\n",
              "      <th>Total Bags</th>\n",
              "      <th>Small Bags</th>\n",
              "      <th>Large Bags</th>\n",
              "      <th>XLarge Bags</th>\n",
              "      <th>type</th>\n",
              "      <th>year</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.33</td>\n",
              "      <td>1036.74</td>\n",
              "      <td>54454.85</td>\n",
              "      <td>48.16</td>\n",
              "      <td>8696.87</td>\n",
              "      <td>8603.62</td>\n",
              "      <td>93.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>Albany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.35</td>\n",
              "      <td>674.28</td>\n",
              "      <td>44638.81</td>\n",
              "      <td>58.33</td>\n",
              "      <td>9505.56</td>\n",
              "      <td>9408.07</td>\n",
              "      <td>97.49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>Albany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.93</td>\n",
              "      <td>794.70</td>\n",
              "      <td>109149.67</td>\n",
              "      <td>130.50</td>\n",
              "      <td>8145.35</td>\n",
              "      <td>8042.21</td>\n",
              "      <td>103.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>Albany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.08</td>\n",
              "      <td>1132.00</td>\n",
              "      <td>71976.41</td>\n",
              "      <td>72.58</td>\n",
              "      <td>5811.16</td>\n",
              "      <td>5677.40</td>\n",
              "      <td>133.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>Albany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.28</td>\n",
              "      <td>941.48</td>\n",
              "      <td>43838.39</td>\n",
              "      <td>75.78</td>\n",
              "      <td>6183.95</td>\n",
              "      <td>5986.26</td>\n",
              "      <td>197.69</td>\n",
              "      <td>0.0</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>Albany</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4506194-7fd1-4667-9148-8c5de577cf00')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e4506194-7fd1-4667-9148-8c5de577cf00 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e4506194-7fd1-4667-9148-8c5de577cf00');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avocodo.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tghq5Z0OmETj",
        "outputId": "7614e8e5-19fb-46d0-dd91-10b0714087b4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 18249 entries, 0 to 18248\n",
            "Data columns (total 11 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   AveragePrice  18249 non-null  float64\n",
            " 1   Small Hass    18249 non-null  float64\n",
            " 2   Large Hass    18249 non-null  float64\n",
            " 3   XLarge Hass   18249 non-null  float64\n",
            " 4   Total Bags    18249 non-null  float64\n",
            " 5   Small Bags    18249 non-null  float64\n",
            " 6   Large Bags    18249 non-null  float64\n",
            " 7   XLarge Bags   18249 non-null  float64\n",
            " 8   type          18249 non-null  object \n",
            " 9   year          18249 non-null  int64  \n",
            " 10  region        18249 non-null  object \n",
            "dtypes: float64(8), int64(1), object(2)\n",
            "memory usage: 1.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()"
      ],
      "metadata": {
        "id": "-ZA4V4Ywm_WW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = avocodo.loc[:,'Small Hass':'XLarge Bags'] = sc.fit_transform(avocodo.loc[:,'Small Hass':'XLarge Bags'])\n",
        "B = pd.get_dummies(avocodo[['type','year','region']],drop_first=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBXWRdjIJODt",
        "outputId": "23652b0b-0d33-4833-d586-a1c81de3b9cf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-9ac953bfb84f>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  A = avocodo.loc[:,'Small Hass':'XLarge Bags'] = sc.fit_transform(avocodo.loc[:,'Small Hass':'XLarge Bags'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.concatenate([A,B], axis = 1)"
      ],
      "metadata": {
        "id": "OIwPi7E3JWvt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = avocodo.iloc[:,0].values"
      ],
      "metadata": {
        "id": "J21gYjTfJgdL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = sc.fit_transform(y.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "Mjsv7BG7JsuU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFomaWkPJ3XC",
        "outputId": "0559dc0f-b80b-431b-d852-c8eb21607f09"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.23081597, -0.1999022 , -0.21209136, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.23110251, -0.20805446, -0.21199672, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.23100731, -0.1544779 , -0.21132513, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       ...,\n",
              "       [-0.2306933 , -0.24309014, -0.20576554, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [-0.2304279 , -0.24265143, -0.20577419, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [-0.22934712, -0.24317042, -0.21045012, ...,  0.        ,\n",
              "         0.        ,  1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEdSB2nZJ9RN",
        "outputId": "938a80c1-021e-4c89-8981-fcee80bc74a2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.18868864],\n",
              "       [-0.13901962],\n",
              "       [-1.18206895],\n",
              "       ...,\n",
              "       [ 1.15237477],\n",
              "       [ 1.30138182],\n",
              "       [ 0.53151208]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train,y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n"
      ],
      "metadata": {
        "id": "MkuXS0vAKJKq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting Multiple Linear Regression to the Training set"
      ],
      "metadata": {
        "id": "TO3ngS_lKVLG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "#import the LinearRegression class from sklearn package\n",
        "regressor = LinearRegression()"
      ],
      "metadata": {
        "id": "R2JSsKcHKaLl"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creaet the regressor object for LineareRegression\n",
        "regressor.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "iQcGS-8kKgpN",
        "outputId": "c1efdfe6-9e16-417d-e5b6-40ca54bd4fec"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(x_test)"
      ],
      "metadata": {
        "id": "gNwkT5YdKl7T"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can confirm the R2 value (moreover, get the R2 Adj.value) of the model by statsmodels library of python"
      ],
      "metadata": {
        "id": "CPE_nta5KsZ6"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "x_train = sm.add_constant(x_train) # adding a constant\n",
        "model = sm.OLS(y_train, x_train).fit()\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmQd-CNMK04L",
        "outputId": "f7ebfecc-5d15-4ad2-9d07-c258a53a7434"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.561\n",
            "Model:                            OLS   Adj. R-squared:                  0.559\n",
            "Method:                 Least Squares   F-statistic:                     299.0\n",
            "Date:                Wed, 12 Apr 2023   Prob (F-statistic):               0.00\n",
            "Time:                        11:13:35   Log-Likelihood:                -14730.\n",
            "No. Observations:               14599   AIC:                         2.959e+04\n",
            "Df Residuals:                   14536   BIC:                         3.006e+04\n",
            "Df Model:                          62                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       -189.6900     12.097    -15.680      0.000    -213.402    -165.978\n",
            "x1             0.0127      0.021      0.605      0.545      -0.028       0.054\n",
            "x2            -0.0220      0.024     -0.930      0.352      -0.068       0.024\n",
            "x3            -0.0213      0.014     -1.563      0.118      -0.048       0.005\n",
            "x4         -7.337e+04   8.28e+04     -0.886      0.376   -2.36e+05     8.9e+04\n",
            "x5          5.551e+04   6.27e+04      0.886      0.376   -6.73e+04    1.78e+05\n",
            "x6          1.815e+04   2.05e+04      0.886      0.376    -2.2e+04    5.83e+04\n",
            "x7          1316.3048   1486.035      0.886      0.376   -1596.513    4229.122\n",
            "x8             0.0940      0.006     15.661      0.000       0.082       0.106\n",
            "x9             1.2222      0.012    104.765      0.000       1.199       1.245\n",
            "x10           -0.5628      0.057     -9.820      0.000      -0.675      -0.450\n",
            "x11           -0.0643      0.057     -1.134      0.257      -0.176       0.047\n",
            "x12           -0.4769      0.057     -8.334      0.000      -0.589      -0.365\n",
            "x13           -0.1027      0.057     -1.801      0.072      -0.214       0.009\n",
            "x14           -0.1235      0.057     -2.156      0.031      -0.236      -0.011\n",
            "x15           -0.4271      0.058     -7.346      0.000      -0.541      -0.313\n",
            "x16            0.1321      0.057      2.300      0.021       0.020       0.245\n",
            "x17            0.0220      0.057      0.383      0.702      -0.091       0.135\n",
            "x18           -0.8765      0.057    -15.409      0.000      -0.988      -0.765\n",
            "x19           -0.7524      0.057    -13.238      0.000      -0.864      -0.641\n",
            "x20           -1.1851      0.057    -20.750      0.000      -1.297      -1.073\n",
            "x21           -0.7891      0.057    -13.801      0.000      -0.901      -0.677\n",
            "x22           -0.7295      0.057    -12.798      0.000      -0.841      -0.618\n",
            "x23           -0.1220      0.057     -2.133      0.033      -0.234      -0.010\n",
            "x24           -0.5976      0.059    -10.137      0.000      -0.713      -0.482\n",
            "x25           -0.0933      0.057     -1.633      0.103      -0.205       0.019\n",
            "x26            0.6321      0.057     11.077      0.000       0.520       0.744\n",
            "x27           -1.2371      0.057    -21.690      0.000      -1.349      -1.125\n",
            "x28           -0.6147      0.057    -10.836      0.000      -0.726      -0.503\n",
            "x29           -0.1180      0.057     -2.070      0.039      -0.230      -0.006\n",
            "x30           -0.4288      0.057     -7.543      0.000      -0.540      -0.317\n",
            "x31           -0.8696      0.058    -14.988      0.000      -0.983      -0.756\n",
            "x32           -0.7040      0.057    -12.354      0.000      -0.816      -0.592\n",
            "x33           -0.3405      0.057     -5.968      0.000      -0.452      -0.229\n",
            "x34           -0.3741      0.057     -6.537      0.000      -0.486      -0.262\n",
            "x35           -0.8552      0.057    -14.977      0.000      -0.967      -0.743\n",
            "x36           -0.6319      0.057    -11.032      0.000      -0.744      -0.520\n",
            "x37            0.4326      0.057      7.538      0.000       0.320       0.545\n",
            "x38            0.1410      0.062      2.267      0.023       0.019       0.263\n",
            "x39           -0.2043      0.057     -3.615      0.000      -0.315      -0.094\n",
            "x40           -0.1266      0.057     -2.218      0.027      -0.238      -0.015\n",
            "x41            0.1866      0.057      3.257      0.001       0.074       0.299\n",
            "x42           -0.8303      0.056    -14.731      0.000      -0.941      -0.720\n",
            "x43           -0.4704      0.057     -8.292      0.000      -0.582      -0.359\n",
            "x44           -0.3176      0.058     -5.493      0.000      -0.431      -0.204\n",
            "x45           -0.6334      0.057    -11.037      0.000      -0.746      -0.521\n",
            "x46           -0.0084      0.057     -0.148      0.882      -0.119       0.103\n",
            "x47           -0.6730      0.057    -11.798      0.000      -0.785      -0.561\n",
            "x48           -0.7903      0.057    -13.981      0.000      -0.901      -0.679\n",
            "x49            0.1565      0.057      2.736      0.006       0.044       0.269\n",
            "x50           -0.3688      0.058     -6.402      0.000      -0.482      -0.256\n",
            "x51            0.5982      0.057     10.468      0.000       0.486       0.710\n",
            "x52           -0.3314      0.057     -5.850      0.000      -0.442      -0.220\n",
            "x53           -0.3771      0.057     -6.621      0.000      -0.489      -0.265\n",
            "x54           -1.1394      0.059    -19.410      0.000      -1.254      -1.024\n",
            "x55           -0.3954      0.058     -6.764      0.000      -0.510      -0.281\n",
            "x56           -0.3235      0.057     -5.628      0.000      -0.436      -0.211\n",
            "x57           -0.3509      0.057     -6.162      0.000      -0.462      -0.239\n",
            "x58           -0.1133      0.057     -1.985      0.047      -0.225      -0.001\n",
            "x59           -0.3717      0.057     -6.495      0.000      -0.484      -0.260\n",
            "x60           -0.4628      0.070     -6.572      0.000      -0.601      -0.325\n",
            "x61           -0.6444      0.059    -10.911      0.000      -0.760      -0.529\n",
            "x62           -0.7221      0.057    -12.712      0.000      -0.833      -0.611\n",
            "==============================================================================\n",
            "Omnibus:                     1081.416   Durbin-Watson:                   1.994\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2579.569\n",
            "Skew:                           0.457   Prob(JB):                         0.00\n",
            "Kurtosis:                       4.845   Cond. No.                     3.88e+10\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 3.95e-11. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#OR"
      ],
      "metadata": {
        "id": "L0Ec7HoOLmBq"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import statsmodels.api as sm\n",
        " regressor_OLS = sm.OLS(endog=y_train, exog=x_train).fit()\n",
        "\n",
        " regressor_OLS.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fH_7LklQLTGx",
        "outputId": "1f5c226c-6df6-4ff1-ec35-f5cd6016d989"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.561\n",
              "Model:                            OLS   Adj. R-squared:                  0.559\n",
              "Method:                 Least Squares   F-statistic:                     299.0\n",
              "Date:                Wed, 12 Apr 2023   Prob (F-statistic):               0.00\n",
              "Time:                        11:15:59   Log-Likelihood:                -14730.\n",
              "No. Observations:               14599   AIC:                         2.959e+04\n",
              "Df Residuals:                   14536   BIC:                         3.006e+04\n",
              "Df Model:                          62                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const       -189.6900     12.097    -15.680      0.000    -213.402    -165.978\n",
              "x1             0.0127      0.021      0.605      0.545      -0.028       0.054\n",
              "x2            -0.0220      0.024     -0.930      0.352      -0.068       0.024\n",
              "x3            -0.0213      0.014     -1.563      0.118      -0.048       0.005\n",
              "x4         -7.337e+04   8.28e+04     -0.886      0.376   -2.36e+05     8.9e+04\n",
              "x5          5.551e+04   6.27e+04      0.886      0.376   -6.73e+04    1.78e+05\n",
              "x6          1.815e+04   2.05e+04      0.886      0.376    -2.2e+04    5.83e+04\n",
              "x7          1316.3048   1486.035      0.886      0.376   -1596.513    4229.122\n",
              "x8             0.0940      0.006     15.661      0.000       0.082       0.106\n",
              "x9             1.2222      0.012    104.765      0.000       1.199       1.245\n",
              "x10           -0.5628      0.057     -9.820      0.000      -0.675      -0.450\n",
              "x11           -0.0643      0.057     -1.134      0.257      -0.176       0.047\n",
              "x12           -0.4769      0.057     -8.334      0.000      -0.589      -0.365\n",
              "x13           -0.1027      0.057     -1.801      0.072      -0.214       0.009\n",
              "x14           -0.1235      0.057     -2.156      0.031      -0.236      -0.011\n",
              "x15           -0.4271      0.058     -7.346      0.000      -0.541      -0.313\n",
              "x16            0.1321      0.057      2.300      0.021       0.020       0.245\n",
              "x17            0.0220      0.057      0.383      0.702      -0.091       0.135\n",
              "x18           -0.8765      0.057    -15.409      0.000      -0.988      -0.765\n",
              "x19           -0.7524      0.057    -13.238      0.000      -0.864      -0.641\n",
              "x20           -1.1851      0.057    -20.750      0.000      -1.297      -1.073\n",
              "x21           -0.7891      0.057    -13.801      0.000      -0.901      -0.677\n",
              "x22           -0.7295      0.057    -12.798      0.000      -0.841      -0.618\n",
              "x23           -0.1220      0.057     -2.133      0.033      -0.234      -0.010\n",
              "x24           -0.5976      0.059    -10.137      0.000      -0.713      -0.482\n",
              "x25           -0.0933      0.057     -1.633      0.103      -0.205       0.019\n",
              "x26            0.6321      0.057     11.077      0.000       0.520       0.744\n",
              "x27           -1.2371      0.057    -21.690      0.000      -1.349      -1.125\n",
              "x28           -0.6147      0.057    -10.836      0.000      -0.726      -0.503\n",
              "x29           -0.1180      0.057     -2.070      0.039      -0.230      -0.006\n",
              "x30           -0.4288      0.057     -7.543      0.000      -0.540      -0.317\n",
              "x31           -0.8696      0.058    -14.988      0.000      -0.983      -0.756\n",
              "x32           -0.7040      0.057    -12.354      0.000      -0.816      -0.592\n",
              "x33           -0.3405      0.057     -5.968      0.000      -0.452      -0.229\n",
              "x34           -0.3741      0.057     -6.537      0.000      -0.486      -0.262\n",
              "x35           -0.8552      0.057    -14.977      0.000      -0.967      -0.743\n",
              "x36           -0.6319      0.057    -11.032      0.000      -0.744      -0.520\n",
              "x37            0.4326      0.057      7.538      0.000       0.320       0.545\n",
              "x38            0.1410      0.062      2.267      0.023       0.019       0.263\n",
              "x39           -0.2043      0.057     -3.615      0.000      -0.315      -0.094\n",
              "x40           -0.1266      0.057     -2.218      0.027      -0.238      -0.015\n",
              "x41            0.1866      0.057      3.257      0.001       0.074       0.299\n",
              "x42           -0.8303      0.056    -14.731      0.000      -0.941      -0.720\n",
              "x43           -0.4704      0.057     -8.292      0.000      -0.582      -0.359\n",
              "x44           -0.3176      0.058     -5.493      0.000      -0.431      -0.204\n",
              "x45           -0.6334      0.057    -11.037      0.000      -0.746      -0.521\n",
              "x46           -0.0084      0.057     -0.148      0.882      -0.119       0.103\n",
              "x47           -0.6730      0.057    -11.798      0.000      -0.785      -0.561\n",
              "x48           -0.7903      0.057    -13.981      0.000      -0.901      -0.679\n",
              "x49            0.1565      0.057      2.736      0.006       0.044       0.269\n",
              "x50           -0.3688      0.058     -6.402      0.000      -0.482      -0.256\n",
              "x51            0.5982      0.057     10.468      0.000       0.486       0.710\n",
              "x52           -0.3314      0.057     -5.850      0.000      -0.442      -0.220\n",
              "x53           -0.3771      0.057     -6.621      0.000      -0.489      -0.265\n",
              "x54           -1.1394      0.059    -19.410      0.000      -1.254      -1.024\n",
              "x55           -0.3954      0.058     -6.764      0.000      -0.510      -0.281\n",
              "x56           -0.3235      0.057     -5.628      0.000      -0.436      -0.211\n",
              "x57           -0.3509      0.057     -6.162      0.000      -0.462      -0.239\n",
              "x58           -0.1133      0.057     -1.985      0.047      -0.225      -0.001\n",
              "x59           -0.3717      0.057     -6.495      0.000      -0.484      -0.260\n",
              "x60           -0.4628      0.070     -6.572      0.000      -0.601      -0.325\n",
              "x61           -0.6444      0.059    -10.911      0.000      -0.760      -0.529\n",
              "x62           -0.7221      0.057    -12.712      0.000      -0.833      -0.611\n",
              "==============================================================================\n",
              "Omnibus:                     1081.416   Durbin-Watson:                   1.994\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2579.569\n",
              "Skew:                           0.457   Prob(JB):                         0.00\n",
              "Kurtosis:                       4.845   Cond. No.                     3.88e+10\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The smallest eigenvalue is 3.95e-11. This might indicate that there are\n",
              "strong multicollinearity problems or that the design matrix is singular.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.561</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.559</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   299.0</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Wed, 12 Apr 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>11:15:59</td>     <th>  Log-Likelihood:    </th> <td> -14730.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td> 14599</td>      <th>  AIC:               </th> <td>2.959e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td> 14536</td>      <th>  BIC:               </th> <td>3.006e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    62</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td> -189.6900</td> <td>   12.097</td> <td>  -15.680</td> <td> 0.000</td> <td> -213.402</td> <td> -165.978</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>    0.0127</td> <td>    0.021</td> <td>    0.605</td> <td> 0.545</td> <td>   -0.028</td> <td>    0.054</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>   -0.0220</td> <td>    0.024</td> <td>   -0.930</td> <td> 0.352</td> <td>   -0.068</td> <td>    0.024</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>   -0.0213</td> <td>    0.014</td> <td>   -1.563</td> <td> 0.118</td> <td>   -0.048</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>-7.337e+04</td> <td> 8.28e+04</td> <td>   -0.886</td> <td> 0.376</td> <td>-2.36e+05</td> <td>  8.9e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td> 5.551e+04</td> <td> 6.27e+04</td> <td>    0.886</td> <td> 0.376</td> <td>-6.73e+04</td> <td> 1.78e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td> 1.815e+04</td> <td> 2.05e+04</td> <td>    0.886</td> <td> 0.376</td> <td> -2.2e+04</td> <td> 5.83e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td> 1316.3048</td> <td> 1486.035</td> <td>    0.886</td> <td> 0.376</td> <td>-1596.513</td> <td> 4229.122</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>    0.0940</td> <td>    0.006</td> <td>   15.661</td> <td> 0.000</td> <td>    0.082</td> <td>    0.106</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x9</th>    <td>    1.2222</td> <td>    0.012</td> <td>  104.765</td> <td> 0.000</td> <td>    1.199</td> <td>    1.245</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x10</th>   <td>   -0.5628</td> <td>    0.057</td> <td>   -9.820</td> <td> 0.000</td> <td>   -0.675</td> <td>   -0.450</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x11</th>   <td>   -0.0643</td> <td>    0.057</td> <td>   -1.134</td> <td> 0.257</td> <td>   -0.176</td> <td>    0.047</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x12</th>   <td>   -0.4769</td> <td>    0.057</td> <td>   -8.334</td> <td> 0.000</td> <td>   -0.589</td> <td>   -0.365</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x13</th>   <td>   -0.1027</td> <td>    0.057</td> <td>   -1.801</td> <td> 0.072</td> <td>   -0.214</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x14</th>   <td>   -0.1235</td> <td>    0.057</td> <td>   -2.156</td> <td> 0.031</td> <td>   -0.236</td> <td>   -0.011</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x15</th>   <td>   -0.4271</td> <td>    0.058</td> <td>   -7.346</td> <td> 0.000</td> <td>   -0.541</td> <td>   -0.313</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x16</th>   <td>    0.1321</td> <td>    0.057</td> <td>    2.300</td> <td> 0.021</td> <td>    0.020</td> <td>    0.245</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x17</th>   <td>    0.0220</td> <td>    0.057</td> <td>    0.383</td> <td> 0.702</td> <td>   -0.091</td> <td>    0.135</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x18</th>   <td>   -0.8765</td> <td>    0.057</td> <td>  -15.409</td> <td> 0.000</td> <td>   -0.988</td> <td>   -0.765</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x19</th>   <td>   -0.7524</td> <td>    0.057</td> <td>  -13.238</td> <td> 0.000</td> <td>   -0.864</td> <td>   -0.641</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x20</th>   <td>   -1.1851</td> <td>    0.057</td> <td>  -20.750</td> <td> 0.000</td> <td>   -1.297</td> <td>   -1.073</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x21</th>   <td>   -0.7891</td> <td>    0.057</td> <td>  -13.801</td> <td> 0.000</td> <td>   -0.901</td> <td>   -0.677</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x22</th>   <td>   -0.7295</td> <td>    0.057</td> <td>  -12.798</td> <td> 0.000</td> <td>   -0.841</td> <td>   -0.618</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x23</th>   <td>   -0.1220</td> <td>    0.057</td> <td>   -2.133</td> <td> 0.033</td> <td>   -0.234</td> <td>   -0.010</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x24</th>   <td>   -0.5976</td> <td>    0.059</td> <td>  -10.137</td> <td> 0.000</td> <td>   -0.713</td> <td>   -0.482</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x25</th>   <td>   -0.0933</td> <td>    0.057</td> <td>   -1.633</td> <td> 0.103</td> <td>   -0.205</td> <td>    0.019</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x26</th>   <td>    0.6321</td> <td>    0.057</td> <td>   11.077</td> <td> 0.000</td> <td>    0.520</td> <td>    0.744</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x27</th>   <td>   -1.2371</td> <td>    0.057</td> <td>  -21.690</td> <td> 0.000</td> <td>   -1.349</td> <td>   -1.125</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x28</th>   <td>   -0.6147</td> <td>    0.057</td> <td>  -10.836</td> <td> 0.000</td> <td>   -0.726</td> <td>   -0.503</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x29</th>   <td>   -0.1180</td> <td>    0.057</td> <td>   -2.070</td> <td> 0.039</td> <td>   -0.230</td> <td>   -0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x30</th>   <td>   -0.4288</td> <td>    0.057</td> <td>   -7.543</td> <td> 0.000</td> <td>   -0.540</td> <td>   -0.317</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x31</th>   <td>   -0.8696</td> <td>    0.058</td> <td>  -14.988</td> <td> 0.000</td> <td>   -0.983</td> <td>   -0.756</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x32</th>   <td>   -0.7040</td> <td>    0.057</td> <td>  -12.354</td> <td> 0.000</td> <td>   -0.816</td> <td>   -0.592</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x33</th>   <td>   -0.3405</td> <td>    0.057</td> <td>   -5.968</td> <td> 0.000</td> <td>   -0.452</td> <td>   -0.229</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x34</th>   <td>   -0.3741</td> <td>    0.057</td> <td>   -6.537</td> <td> 0.000</td> <td>   -0.486</td> <td>   -0.262</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x35</th>   <td>   -0.8552</td> <td>    0.057</td> <td>  -14.977</td> <td> 0.000</td> <td>   -0.967</td> <td>   -0.743</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x36</th>   <td>   -0.6319</td> <td>    0.057</td> <td>  -11.032</td> <td> 0.000</td> <td>   -0.744</td> <td>   -0.520</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x37</th>   <td>    0.4326</td> <td>    0.057</td> <td>    7.538</td> <td> 0.000</td> <td>    0.320</td> <td>    0.545</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x38</th>   <td>    0.1410</td> <td>    0.062</td> <td>    2.267</td> <td> 0.023</td> <td>    0.019</td> <td>    0.263</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x39</th>   <td>   -0.2043</td> <td>    0.057</td> <td>   -3.615</td> <td> 0.000</td> <td>   -0.315</td> <td>   -0.094</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x40</th>   <td>   -0.1266</td> <td>    0.057</td> <td>   -2.218</td> <td> 0.027</td> <td>   -0.238</td> <td>   -0.015</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x41</th>   <td>    0.1866</td> <td>    0.057</td> <td>    3.257</td> <td> 0.001</td> <td>    0.074</td> <td>    0.299</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x42</th>   <td>   -0.8303</td> <td>    0.056</td> <td>  -14.731</td> <td> 0.000</td> <td>   -0.941</td> <td>   -0.720</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x43</th>   <td>   -0.4704</td> <td>    0.057</td> <td>   -8.292</td> <td> 0.000</td> <td>   -0.582</td> <td>   -0.359</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x44</th>   <td>   -0.3176</td> <td>    0.058</td> <td>   -5.493</td> <td> 0.000</td> <td>   -0.431</td> <td>   -0.204</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x45</th>   <td>   -0.6334</td> <td>    0.057</td> <td>  -11.037</td> <td> 0.000</td> <td>   -0.746</td> <td>   -0.521</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x46</th>   <td>   -0.0084</td> <td>    0.057</td> <td>   -0.148</td> <td> 0.882</td> <td>   -0.119</td> <td>    0.103</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x47</th>   <td>   -0.6730</td> <td>    0.057</td> <td>  -11.798</td> <td> 0.000</td> <td>   -0.785</td> <td>   -0.561</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x48</th>   <td>   -0.7903</td> <td>    0.057</td> <td>  -13.981</td> <td> 0.000</td> <td>   -0.901</td> <td>   -0.679</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x49</th>   <td>    0.1565</td> <td>    0.057</td> <td>    2.736</td> <td> 0.006</td> <td>    0.044</td> <td>    0.269</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x50</th>   <td>   -0.3688</td> <td>    0.058</td> <td>   -6.402</td> <td> 0.000</td> <td>   -0.482</td> <td>   -0.256</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x51</th>   <td>    0.5982</td> <td>    0.057</td> <td>   10.468</td> <td> 0.000</td> <td>    0.486</td> <td>    0.710</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x52</th>   <td>   -0.3314</td> <td>    0.057</td> <td>   -5.850</td> <td> 0.000</td> <td>   -0.442</td> <td>   -0.220</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x53</th>   <td>   -0.3771</td> <td>    0.057</td> <td>   -6.621</td> <td> 0.000</td> <td>   -0.489</td> <td>   -0.265</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x54</th>   <td>   -1.1394</td> <td>    0.059</td> <td>  -19.410</td> <td> 0.000</td> <td>   -1.254</td> <td>   -1.024</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x55</th>   <td>   -0.3954</td> <td>    0.058</td> <td>   -6.764</td> <td> 0.000</td> <td>   -0.510</td> <td>   -0.281</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x56</th>   <td>   -0.3235</td> <td>    0.057</td> <td>   -5.628</td> <td> 0.000</td> <td>   -0.436</td> <td>   -0.211</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x57</th>   <td>   -0.3509</td> <td>    0.057</td> <td>   -6.162</td> <td> 0.000</td> <td>   -0.462</td> <td>   -0.239</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x58</th>   <td>   -0.1133</td> <td>    0.057</td> <td>   -1.985</td> <td> 0.047</td> <td>   -0.225</td> <td>   -0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x59</th>   <td>   -0.3717</td> <td>    0.057</td> <td>   -6.495</td> <td> 0.000</td> <td>   -0.484</td> <td>   -0.260</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x60</th>   <td>   -0.4628</td> <td>    0.070</td> <td>   -6.572</td> <td> 0.000</td> <td>   -0.601</td> <td>   -0.325</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x61</th>   <td>   -0.6444</td> <td>    0.059</td> <td>  -10.911</td> <td> 0.000</td> <td>   -0.760</td> <td>   -0.529</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x62</th>   <td>   -0.7221</td> <td>    0.057</td> <td>  -12.712</td> <td> 0.000</td> <td>   -0.833</td> <td>   -0.611</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>1081.416</td> <th>  Durbin-Watson:     </th> <td>   1.994</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2579.569</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>           <td> 0.457</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>       <td> 4.845</td>  <th>  Cond. No.          </th> <td>3.88e+10</td>\n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 3.95e-11. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}